{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1: Feature Extraction and SVM Classification**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Overview**\n",
    "\n",
    "This part focuses on extracting features from image masks and using them to train an SVM model. The goal is to classify images based on these extracted features.\n",
    "\n",
    "#### **Key Steps:**\n",
    "\n",
    "1. **Image Mask Preprocessing:**\n",
    "   - Load and preprocess the image masks to a standard format.\n",
    "\n",
    "2. **Feature Extraction:**\n",
    "   - Extract features like area, perimeter, Hu moments, etc., from the masks.\n",
    "\n",
    "3. **Feature Selection:**\n",
    "   - Use `SelectKBest` to identify the most important features for classification.\n",
    "\n",
    "4. **SVM Training:**\n",
    "   - Train an SVM model using the selected features and evaluate its performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 2: CNN-based Image Classification**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Overview**\n",
    "\n",
    "This part employs Convolutional Neural Networks (CNNs) to classify images. We use either a custom CNN or a pre-trained ResNet50 model.\n",
    "\n",
    "#### **Key Steps:**\n",
    "\n",
    "1. **Image Preprocessing:**\n",
    "   - Load and preprocess images for CNN input.\n",
    "\n",
    "2. **Model Building:**\n",
    "   - Build and train a CNN model, either custom or based on ResNet50.\n",
    "\n",
    "3. **Evaluation:**\n",
    "   - Evaluate model performance using metrics like accuracy and confusion matrix.\n",
    "\n",
    "4. **Model Interpretation:**\n",
    "   - Use Grad-CAM to visualize which parts of the image influenced the model's decisions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "This project combines feature-based SVM classification with deep learning using CNNs, providing a comprehensive approach to image classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Part 1: Feature Extraction and SVM Classification**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the FeatureExtractor class from the feature_extraction module\n",
    "from part1_manual_extraction.feature_extraction import FeatureExtractor\n",
    "\n",
    "# Set up the paths\n",
    "image_directory = '../datasets/segmentation_final/masks/Andrea/'\n",
    "labels_csv_path = '../datasets/segmentation_final/masks/annotations.csv'\n",
    "output_path = '../cibei_project/part1_manual_extraction/processed_data/processed_data.joblib'\n",
    "num_features = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    image_directory=image_directory,\n",
    "    labels_csv_path=labels_csv_path,\n",
    "    output_path=output_path,\n",
    "    num_features=num_features,\n",
    ")\n",
    "\n",
    "feature_extractor.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part1_manual_extraction.feature_plots import FeaturePlotter\n",
    "# Initialize and load data\n",
    "plotter = FeaturePlotter(csv_path='../cibei_project/part1_manual_extraction/processed_data/original_features.csv')\n",
    "plotter.load_data()\n",
    "\n",
    "# List available features\n",
    "available_features = plotter.list_available_features()\n",
    "print(available_features)\n",
    "feature_names=['Extent', 'Solidity', 'Pixels_at_height_mean','Area','Compactness','Perimeter','Hu_1','Width']\n",
    "\n",
    "# Plot distributions for the selected features\n",
    "plotter.plot_features_distribution_with_intersection(feature_names=feature_names)\n",
    "\n",
    "# Plot t-SNE for selected features\n",
    "plotter.plot_tsne(feature_names=feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ModelTrainer class from the model_training module\n",
    "from part1_manual_extraction.model_training import ModelTrainer\n",
    "\n",
    "# Set up the paths\n",
    "annotations_path = '../datasets/segmentation_final/masks/annotations.csv'\n",
    "processed_data_path = '../cibei_project/part1_manual_extraction/processed_data/standardized_features.joblib'\n",
    "output_directory = '../cibei_project/part1_manual_extraction/results/'\n",
    "image_directory = '../datasets/segmentation_final/masks/Andrea/'\n",
    "original_images_directories = [\n",
    "        \"../datasets/segmentation_final/SQR_YOLO/Andrea/fold_1/train/images/\",\n",
    "        \"../datasets/segmentation_final/SQR_YOLO/Andrea/fold_2/train/images/\",\n",
    "        \"../datasets/segmentation_final/SQR_YOLO/Andrea/fold_3/train/images/\",\n",
    "        \"../datasets/segmentation_final/SQR_YOLO/Andrea/fold_4/train/images/\",\n",
    "        \"../datasets/segmentation_final/SQR_YOLO/Andrea/fold_5/train/images/\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the model trainer\n",
    "model_trainer = ModelTrainer(\n",
    "    annotations_path=annotations_path,\n",
    "    processed_data_path=processed_data_path,\n",
    "    output_directory=output_directory,\n",
    "    image_directory=image_directory,\n",
    "    original_images_directories=original_images_directories\n",
    ")\n",
    "model_trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature name\n",
    "feature_name = 'Pixels_at_height_mean'\n",
    "\n",
    "# Intersection for Pixels_at_height_mean\n",
    "intersection_point = 69.91  \n",
    "\n",
    "# Save images based on the feature and intersection point\n",
    "model_trainer.save_images_based_on_feature(feature_name=feature_name, intersection_point=intersection_point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Part 2: CNN-based Image Classification**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CNNModel class\n",
    "from part2_CNNmodel.cnn_model import CNNModel\n",
    "\n",
    "# Initialize CNNModel\n",
    "cnn_model = CNNModel(\n",
    "    annotations_path='../datasets/segmentation_final/masks/annotations.csv',\n",
    "    image_directory='../datasets/segmentation_final/masks/Andrea/',\n",
    "    output_directory='../cibei_project/part2_CNNmodel/results/',\n",
    "    model_type='resnet50' \n",
    ")\n",
    "\n",
    "# Run the entire training pipeline\n",
    "cnn_model.run_training_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CNNModel class\n",
    "from part2_CNNmodel.cnn_model import CNNModel\n",
    "\n",
    "# Initialize CNNModel\n",
    "cnn_model = CNNModel(\n",
    "    annotations_path='../datasets/segmentation_final/masks/annotations.csv',\n",
    "    image_directory='../datasets/segmentation_final/masks/Andrea/',\n",
    "    output_directory='../cibei_project/part2_CNNmodel/results/',\n",
    "    model_type='custom' \n",
    ")\n",
    "\n",
    "# Run the entire training pipeline\n",
    "cnn_model.run_training_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
